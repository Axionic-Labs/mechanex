{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Getting Started with Mechanex"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mechanex as mx"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Loading a Model\n",
                "\n",
                "Mechanex makes it easy to load models locally for experimentation. It automatically configures necessary hook points and SAE releases for you."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load gpt2-small locally\n",
                "mx.set_key(\"your-api-key\")\n",
                "mx.load(\"gpt2-small\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Advanced Sampling\n",
                "\n",
                "You can generate text from the model with standard sampling methods like `top-k` and `top-p`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \"The capital of France is\"\n",
                "\n",
                "print(\"Top-K Sampling:\")\n",
                "out_k = mx.generation.generate(prompt, max_tokens=10, sampling_method=\"top-k\", top_k=50)\n",
                "print(f\"- {out_k}\")\n",
                "\n",
                "print(\"\\nTop-P Sampling:\")\n",
                "out_p = mx.generation.generate(prompt, max_tokens=10, sampling_method=\"top-p\", top_p=0.9)\n",
                "print(f\"- {out_p}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Steering Vectors\n",
                "\n",
                "Steering vectors allow you to nudge the model's internal representations toward specific behaviors. \n",
                "\n",
                "### Generate Vectors\n",
                "We'll create a steering vector that encourages the model to be more \"honest\" using a few examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "honesty_vector_id = mx.steering.generate_vectors(\n",
                "    prompts=[\"I tell the\", \"My statement is\", \"The truth is\"],\n",
                "    positive_answers=[\" truth\", \" factual\", \" correct\"],\n",
                "    negative_answers=[\" lie\", \" false\", \" wrong\"],\n",
                "    method=\"caa\" # Contrastive Activation Addition\n",
                ")\n",
                "print(f\"Generated steering vector with ID: {honesty_vector_id}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save and Load Vectors\n",
                "\n",
                "Mechanex allows you to export steering vectors to files so you can reuse them across sessions without recomputing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the vector to disk\n",
                "mx.steering.save_vectors(honesty_vector_id, \"example_vector.json\")\n",
                "\n",
                "# Load it back as a dictionary of tensors\n",
                "vectors = mx.steering.load_vectors(\"example_vector.json\")\n",
                "\n",
                "print(f\"Loaded layers: {list(vectors.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Steer Generation\n",
                "\n",
                "Now we apply the loaded vector during generation. Note how we can pass the vector dictionary directly or the ID."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "steered_output = mx.generation.generate(\n",
                "    \"Do I tell lies? Answer: \",\n",
                "    max_tokens=20,\n",
                "    steering_vector=\"3c676005-5610-4482-afa4-8b0405a228b0\", # Passing the loaded dict\n",
                "    steering_strength=2.0\n",
                ")\n",
                "print(f\"Steered Output: {steered_output}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Sparse Autoencoders (SAEs)\n",
                "\n",
                "Mechanex integrates with `sae-lens` to automatically download and apply Sparse Autoencoders for concept steering. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "behavior = mx.sae.create_behavior(\n",
                "    \"paris\",\n",
                "    prompts=[\"The city of light is\", \"I love visiting\"],\n",
                "    positive_answers=[\" Paris\", \" Paris\"],\n",
                "    # Negative answers help isolate the concept\n",
                "    negative_answers=[\" London\", \" Rome\"] \n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Steering with SAEs\n",
                "\n",
                "You can also use these behaviors to steer the model towards specific SAE features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sae_steered = mx.sae.generate(\n",
                "    \"Do I want to go to rome or paris? Choose Paris or Rome. Answer:  \",\n",
                "    behavior_names=[\"paris\"],\n",
                "    max_new_tokens=64,\n",
                "    force_steering=[\"paris\"]\n",
                ")\n",
                "print(f\"SAE Steered: {sae_steered}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Remote API Features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mx.unload()\n",
                "\n",
                "ads_output = mx.generation.generate(\n",
                "    \"Here is the story about the history of artificial intelligence:\",\n",
                "    sampling_method=\"ads\",\n",
                "    max_tokens=64\n",
                ")\n",
                "print(f\"ADS Output: {ads_output}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and save behaviors directly in your Axionic account for persistence\n",
                "mx.sae.list_behaviors()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
