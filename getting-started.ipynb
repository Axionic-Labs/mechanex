{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Getting Started with Mechanex"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mechanex as mx"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Loading a Model\n",
                "\n",
                "Mechanex makes it easy to load models locally for experimentation. It automatically configures necessary hook points and SAE releases for you."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading gpt2-small locally...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`torch_dtype` is deprecated! Use `dtype` instead!\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model gpt2-small into HookedTransformer\n",
                        "SAE release automatically set to: gpt2-small-res-jb\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<mechanex.client.Mechanex at 0x129e85940>"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load gpt2-small locally\n",
                "mx.set_key(\"your-api-key\")\n",
                "mx.load(\"gpt2-small\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Advanced Sampling\n",
                "\n",
                "You can generate text from the model with standard sampling methods like `top-k` and `top-p`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Top-K Sampling:\n",
                        "- The capital of France is a sprawling, modern industrial city and its population of\n",
                        "\n",
                        "Top-P Sampling:\n",
                        "- The capital of France is making plans to build 250 additional state-owned factories\n"
                    ]
                }
            ],
            "source": [
                "prompt = \"The capital of France is\"\n",
                "\n",
                "print(\"Top-K Sampling:\")\n",
                "out_k = mx.generation.generate(prompt, max_tokens=10, sampling_method=\"top-k\", top_k=50)\n",
                "print(f\"- {out_k}\")\n",
                "\n",
                "print(\"\\nTop-P Sampling:\")\n",
                "out_p = mx.generation.generate(prompt, max_tokens=10, sampling_method=\"top-p\", top_p=0.9)\n",
                "print(f\"- {out_p}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Steering Vectors\n",
                "\n",
                "Steering vectors allow you to nudge the model's internal representations toward specific behaviors. \n",
                "\n",
                "### Generate Vectors\n",
                "We'll create a steering vector that encourages the model to be more \"honest\" using a few examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing prompts to generate steering vectors...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 3/3 [00:00<00:00, 13.34it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Steering vector computation complete.\n",
                        "Generated steering vector with ID: 62e561f7-597b-47bc-9cf0-5568ef124cc5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "honesty_vector_id = mx.steering.generate_vectors(\n",
                "    prompts=[\"I tell the\", \"My statement is\", \"The truth is\"],\n",
                "    positive_answers=[\" truth\", \" factual\", \" correct\"],\n",
                "    negative_answers=[\" lie\", \" false\", \" wrong\"],\n",
                "    method=\"caa\" # Contrastive Activation Addition\n",
                ")\n",
                "print(f\"Generated steering vector with ID: {honesty_vector_id}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save and Load Vectors\n",
                "\n",
                "Mechanex allows you to export steering vectors to files so you can reuse them across sessions without recomputing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Steering vectors saved to example_vector.json\n",
                        "Steering vectors loaded from example_vector.json\n",
                        "Loaded layers: [8, 9, 10, 11]\n"
                    ]
                }
            ],
            "source": [
                "# Save the vector to disk\n",
                "mx.steering.save_vectors(honesty_vector_id, \"example_vector.json\")\n",
                "\n",
                "# Load it back as a dictionary of tensors\n",
                "vectors = mx.steering.load_vectors(\"example_vector.json\")\n",
                "\n",
                "print(f\"Loaded layers: {list(vectors.keys())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Steer Generation\n",
                "\n",
                "Now we apply the loaded vector during generation. Note how we can pass the vector dictionary directly or the ID."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Steered Output: Do I tell lies? Answer:  Yes . I don't. I tell truthful lies, and I only tell lies to people who\n"
                    ]
                }
            ],
            "source": [
                "steered_output = mx.generation.generate(\n",
                "    \"Do I tell lies? Answer: \",\n",
                "    max_tokens=20,\n",
                "    steering_vector=\"3c676005-5610-4482-afa4-8b0405a228b0\", # Passing the loaded dict\n",
                "    steering_strength=2.0\n",
                ")\n",
                "print(f\"Steered Output: {steered_output}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Sparse Autoencoders (SAEs)\n",
                "\n",
                "Mechanex integrates with `sae-lens` to automatically download and apply Sparse Autoencoders for concept steering. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Remote behavior creation failed ([401] Authentication failed: Invalid API key). Computing locally with sae-lens...\n",
                        "Loading SAE for blocks.8.hook_resid_pre (gpt2-small-res-jb)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/sripkunda/Documents/axionic/mechanex/.venv/lib/python3.13/site-packages/sae_lens/saes/sae.py:248: UserWarning: \n",
                        "This SAE has non-empty model_from_pretrained_kwargs. \n",
                        "For optimal performance, load the model like so:\n",
                        "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "behavior = mx.sae.create_behavior(\n",
                "    \"paris\",\n",
                "    prompts=[\"The city of light is\", \"I love visiting\"],\n",
                "    positive_answers=[\" Paris\", \" Paris\"],\n",
                "    # Negative answers help isolate the concept\n",
                "    negative_answers=[\" London\", \" Rome\"] \n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Steering with SAEs\n",
                "\n",
                "You can also use these behaviors to steer the model towards specific SAE features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2c2a4de5caa84e1eadd9e50789eac214",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/64 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SAE Steered: Do I want to go to rome or paris? Choose Paris or Rome. Answer:   ??? Suspect civility varies. Really. See the whole guide. If you have to do a lot of work though, you should be prepared to become anonymous to be sumptuous from accusations and questions. Look at the list of questions. In most cases, the one you are most (or it's sometimes even\n"
                    ]
                }
            ],
            "source": [
                "sae_steered = mx.sae.generate(\n",
                "    \"Do I want to go to rome or paris? Choose Paris or Rome. Answer:  \",\n",
                "    behavior_names=[\"paris\"],\n",
                "    max_new_tokens=64,\n",
                "    force_steering=[\"paris\"]\n",
                ")\n",
                "print(f\"SAE Steered: {sae_steered}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Remote API Features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "MechanexError",
                    "evalue": "Add balance to your API key in order to use this feature.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mMechanexError\u001b[39m                             Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ads_output = \u001b[43mmx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHere is the story about the history of artificial intelligence:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mADS Output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mads_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/axionic/mechanex/mechanex/generation.py:51\u001b[39m, in \u001b[36mGenerationModule.generate\u001b[39m\u001b[34m(self, prompt, max_tokens, sampling_method, top_k, top_p, steering_strength, steering_vector)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_method == \u001b[33m\"\u001b[39m\u001b[33mads\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MechanexError\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MechanexError(\u001b[33m\"\u001b[39m\u001b[33mAdd balance to your API key in order to use this feature.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_local_methods:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MechanexError\n",
                        "\u001b[31mMechanexError\u001b[39m: Add balance to your API key in order to use this feature."
                    ]
                }
            ],
            "source": [
                "ads_output = mx.generation.generate(\n",
                "    \"Here is the story about the history of artificial intelligence:\",\n",
                "    sampling_method=\"ads\",\n",
                "    max_tokens=64\n",
                ")\n",
                "print(f\"ADS Output: {ads_output}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and save behaviors directly in your Axionic account for persistence\n",
                "mx.sae.list_behaviors()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
