{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "333df122",
         "metadata": {},
         "source": [
            "## Dataset creation\n",
            "\n",
            "Let's make an example dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4bbfa3c7",
         "metadata": {},
         "outputs": [],
         "source": [
            "import json\n",
            "import os\n",
            "import random\n",
            "\n",
            "MAX_EXAMPLES = 5\n",
            "\n",
            "# Toxicity-related prompts\n",
            "toxicity_prompts = [\n",
            "    \"I think that\",\n",
            "    \"People say\",\n",
            "    \"My opinion is\",\n",
            "    \"They are just\",\n",
            "    \"You look like\",\n",
            "    \"Go away you\",\n",
            "    \"Why are you so\",\n",
            "    \"Everyone knows that\",\n",
            "    \"The problem with you is\",\n",
            "    \"I hate it when\",\n",
            "    \"Stop being such a\",\n",
            "    \"You are nothing but a\",\n",
            "    \"Listen here you\",\n",
            "    \"Don't ever talk to me like that you\",\n",
            "    \"You're acting like a\",\n",
            "]\n",
            "\n",
            "# Positive completions (Kind, polite, constructive)\n",
            "positive_templates = [\n",
            "    \" we should all try to get along.\",\n",
            "    \" kindness is important.\",\n",
            "    \" everyone deserves respect.\",\n",
            "    \" being helpful is good.\",\n",
            "    \" a wonderful person.\",\n",
            "    \" beautiful inside and out.\",\n",
            "    \" amazing and talented.\",\n",
            "    \" working hard to improve.\",\n",
            "    \" considerate of others.\",\n",
            "    \" thoughtful and caring.\",\n",
            "    \" full of potential.\",\n",
            "    \" distinct and unique.\",\n",
            "    \" valuable member of the community.\",\n",
            "    \" friend to everyone.\",\n",
            "    \" source of joy.\",\n",
            "]\n",
            "\n",
            "# Negative completions (Toxic, mean, hateful)\n",
            "negative_templates = [\n",
            "    \" stupid idiot.\",\n",
            "    \" waste of space.\",\n",
            "    \" terrible person.\",\n",
            "    \" complete failure.\",\n",
            "    \" ugly mess.\",\n",
            "    \" horrible disappointment.\",\n",
            "    \" hateful loser.\",\n",
            "    \" worthless piece of trash.\",\n",
            "    \" disgusting animal.\",\n",
            "    \" absolute disgrace.\",\n",
            "    \" mindless drone.\",\n",
            "    \" pathetic joke.\",\n",
            "    \" nasty creature.\",\n",
            "    \" rot in hell.\",\n",
            "    \" shut up and leave.\",\n",
            "]\n",
            "\n",
            "# Build dataset\n",
            "dataset = []\n",
            "for prompt in toxicity_prompts:\n",
            "    for _ in range(1):  # multiple variations per prompt\n",
            "        pos = random.choice(positive_templates)\n",
            "        neg = random.choice(negative_templates)\n",
            "        dataset.append({\n",
            "            \"prompt\": prompt,\n",
            "            \"positive_answer\": pos,\n",
            "            \"negative_answer\": neg\n",
            "        })\n",
            "\n",
            "num_added = 0\n",
            "os.makedirs(\"tests\", exist_ok=True)\n",
            "with open(\"tests/example_dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
            "    for item in dataset:\n",
            "        f.write(json.dumps(item) + \"\\n\")\n",
            "        if num_added == MAX_EXAMPLES:\n",
            "            break\n",
            "        num_added += 1\n",
            "print(f\"Created dataset with {num_added} examples\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e817aa31",
         "metadata": {},
         "source": [
            "Now we can import mechanex and load the model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9de23b62",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Set your environment variable\n",
            "%env MECHANEX_API_KEY=915ee7c651f52048829a9dec91c448ea661f2ee2d85cf78b44970da296833047"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "02c45529",
         "metadata": {},
         "outputs": [],
         "source": [
            "import mechanex as mx\n",
            "import os\n",
            "\n",
            "# Set your API key\n",
            "mx.set_key(os.getenv(\"MECHANEX_API_KEY\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f093a1f5",
         "metadata": {},
         "source": [
            "Let's find steering vectors for our data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1feca1be",
         "metadata": {},
         "outputs": [],
         "source": [
            "prompt = \"You are a helpful AI assistant. Answer the userâ€™s question clearly and politely.\\nUser: Where can I buy some good electronics?\\nAssistant:\"\n",
            "original = mx.generation.generate(prompt)\n",
            "print(original)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d22bae8e",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Find steering vectors for a given output and save them into the Axionic steering vector DB\n",
            "vector = mx.steering.generate_from_jsonl(\"./tests/example_dataset.jsonl\", method=\"caa\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "89e491b4",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(vector)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fe63d489",
         "metadata": {},
         "outputs": [],
         "source": [
            "test_prompt = \"I am feeling so \"\n",
            "steered = mx.generation.generate(test_prompt, steering_strength=0.3, steering_vector=\"e74f687a-3d63-4478-a2d5-884ac72005a7\")\n",
            "original = mx.generation.generate(test_prompt)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6c37028b",
         "metadata": {},
         "source": [
            "Printing results:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "22c33a85",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Generate steered and original outputs\n",
            "print(\"Original:\")\n",
            "print(original)\n",
            "print(\"\\n\\n\")\n",
            "print(\"Steered:\")\n",
            "print(steered)\n",
            "print(\"-\" * 25)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "04e78936",
         "metadata": {},
         "source": [
            "We can also vary the sampling method of our original generation."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "08996f74",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(mx.generation.generate(\"Here is the story about the american civil war:\", sampling_method=\"ads\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9b007aed",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 1. Generate steering vector from JSONL\n",
            "# (This still computes the vector first, which is often required)\n",
            "vector_response = mx.steering.generate_from_jsonl(\"./tests/example_dataset.jsonl\", method=\"caa\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5b10b3df",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(vector_response)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "92d7d635",
         "metadata": {},
         "outputs": [],
         "source": [
            "behavior = mx.sae.create_behavior_from_jsonl(\n",
            "    behavior_name=\"toxicity_improved\",\n",
            "    dataset_path=\"./tests/example_dataset.jsonl\",\n",
            "    description=\"Reduces toxic output\",\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b273f34d",
         "metadata": {},
         "outputs": [],
         "source": [
            "mx.sae.list_behaviors()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d95c5cda",
         "metadata": {},
         "outputs": [],
         "source": [
            "response = mx.sae.generate(\n",
            "    prompt=\"How are you feeling about life? I am feeling \",\n",
            "    max_new_tokens=50,\n",
            "    behavior_names=[\"toxicity_improved\"],\n",
            "    auto_correct=True,\n",
            "    force_steering=[\"toxicity_improved\"]\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "46c50d65",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(response)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "bf23ac40",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(mx.generation.generate(\"How are you feeling about life? I am feeling \", sampling_method=\"top-k\"))"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
