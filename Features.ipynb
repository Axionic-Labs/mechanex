{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "333df122",
         "metadata": {},
         "source": [
            "## Dataset creation\n",
            "\n",
            "Let's make an example dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "4bbfa3c7",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Created dataset with 5 examples\n"
               ]
            }
         ],
         "source": [
            "import json\n",
            "import os\n",
            "import random\n",
            "\n",
            "MAX_EXAMPLES = 5\n",
            "\n",
            "# Toxicity-related prompts\n",
            "toxicity_prompts = [\n",
            "    \"I think that\",\n",
            "    \"People say\",\n",
            "    \"My opinion is\",\n",
            "    \"They are just\",\n",
            "    \"You look like\",\n",
            "    \"Go away you\",\n",
            "    \"Why are you so\",\n",
            "    \"Everyone knows that\",\n",
            "    \"The problem with you is\",\n",
            "    \"I hate it when\",\n",
            "    \"Stop being such a\",\n",
            "    \"You are nothing but a\",\n",
            "    \"Listen here you\",\n",
            "    \"Don't ever talk to me like that you\",\n",
            "    \"You're acting like a\",\n",
            "]\n",
            "\n",
            "# Positive completions (Kind, polite, constructive)\n",
            "positive_templates = [\n",
            "    \" we should all try to get along.\",\n",
            "    \" kindness is important.\",\n",
            "    \" everyone deserves respect.\",\n",
            "    \" being helpful is good.\",\n",
            "    \" a wonderful person.\",\n",
            "    \" beautiful inside and out.\",\n",
            "    \" amazing and talented.\",\n",
            "    \" working hard to improve.\",\n",
            "    \" considerate of others.\",\n",
            "    \" thoughtful and caring.\",\n",
            "    \" full of potential.\",\n",
            "    \" distinct and unique.\",\n",
            "    \" valuable member of the community.\",\n",
            "    \" friend to everyone.\",\n",
            "    \" source of joy.\",\n",
            "]\n",
            "\n",
            "# Negative completions (Toxic, mean, hateful)\n",
            "negative_templates = [\n",
            "    \" stupid idiot.\",\n",
            "    \" waste of space.\",\n",
            "    \" terrible person.\",\n",
            "    \" complete failure.\",\n",
            "    \" ugly mess.\",\n",
            "    \" horrible disappointment.\",\n",
            "    \" hateful loser.\",\n",
            "    \" worthless piece of trash.\",\n",
            "    \" disgusting animal.\",\n",
            "    \" absolute disgrace.\",\n",
            "    \" mindless drone.\",\n",
            "    \" pathetic joke.\",\n",
            "    \" nasty creature.\",\n",
            "    \" rot in hell.\",\n",
            "    \" shut up and leave.\",\n",
            "]\n",
            "\n",
            "# Build dataset\n",
            "dataset = []\n",
            "for prompt in toxicity_prompts:\n",
            "    for _ in range(1):  # multiple variations per prompt\n",
            "        pos = random.choice(positive_templates)\n",
            "        neg = random.choice(negative_templates)\n",
            "        dataset.append({\n",
            "            \"prompt\": prompt,\n",
            "            \"positive_answer\": pos,\n",
            "            \"negative_answer\": neg\n",
            "        })\n",
            "\n",
            "num_added = 0\n",
            "os.makedirs(\"tests\", exist_ok=True)\n",
            "with open(\"tests/example_dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
            "    for item in dataset:\n",
            "        f.write(json.dumps(item) + \"\\n\")\n",
            "        if num_added == MAX_EXAMPLES:\n",
            "            break\n",
            "        num_added += 1\n",
            "print(f\"Created dataset with {num_added} examples\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e817aa31",
         "metadata": {},
         "source": [
            "Now we can import mechanex and load the model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "9de23b62",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "env: MECHANEX_API_KEY=915ee7c651f52048829a9dec91c448ea661f2ee2d85cf78b44970da296833047\n"
               ]
            }
         ],
         "source": [
            "# Set your environment variable\n",
            "%env MECHANEX_API_KEY=915ee7c651f52048829a9dec91c448ea661f2ee2d85cf78b44970da296833047"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "02c45529",
         "metadata": {},
         "outputs": [],
         "source": [
            "import mechanex as mx\n",
            "import os\n",
            "\n",
            "# Set your API key\n",
            "mx.set_key(os.getenv(\"MECHANEX_API_KEY\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f093a1f5",
         "metadata": {},
         "source": [
            "Let's find steering vectors for our data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "1feca1be",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "You are a helpful AI assistant. Answer the user’s question clearly and politely.\n",
                  "User: Where can I buy some good electronics?\n",
                  "Assistant: Well, first of all, I'm here to help you find the best place to buy electronics. Let's start with a few key points.\n",
                  "\n",
                  "Electronics can vary in price depending on the brand, quality, and type of product. To find the best deals, I recommend checking the local electronics market or online stores. For specific electronics, the best online shops might be well-known with big names in the industry, such as Amazon or eBay. However, the best places to buy electronics depend on your region and the electronics you wish to purchase. \n",
                  "\n",
                  "To ensure the best quality and value for your money, it's a good idea to compare\n"
               ]
            }
         ],
         "source": [
            "prompt = \"You are a helpful AI assistant. Answer the user’s question clearly and politely.\\nUser: Where can I buy some good electronics?\\nAssistant:\"\n",
            "original = mx.generation.generate(prompt)\n",
            "print(original)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "d22bae8e",
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'mx' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find steering vectors for a given output and save them into the Axionic steering vector DB\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vector = \u001b[43mmx\u001b[49m.steering.generate_from_jsonl(\u001b[33m\"\u001b[39m\u001b[33m./tests/example_dataset.jsonl\u001b[39m\u001b[33m\"\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mcaa\u001b[39m\u001b[33m\"\u001b[39m)\n",
                  "\u001b[31mNameError\u001b[39m: name 'mx' is not defined"
               ]
            }
         ],
         "source": [
            "# Find steering vectors for a given output and save them into the Axionic steering vector DB\n",
            "vector = mx.steering.generate_from_jsonl(\"./tests/example_dataset.jsonl\", method=\"caa\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "89e491b4",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "e74f687a-3d63-4478-a2d5-884ac72005a7\n"
               ]
            }
         ],
         "source": [
            "print(vector)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "fe63d489",
         "metadata": {},
         "outputs": [
            {
               "ename": "MechanexError",
               "evalue": "API request to /generate failed: 400 Client Error: Bad Request for url: http://localhost:8000/generate | Server response: {\"detail\":\"No model loaded\"}",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
                  "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sripk\\OneDrive\\Documents\\Work\\axionic\\mechanex\\mechanex\\base.py:25\u001b[39m, in \u001b[36m_BaseModule._post\u001b[39m\u001b[34m(self, endpoint, data)\u001b[39m\n\u001b[32m     20\u001b[39m response = requests.post(\n\u001b[32m     21\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._client.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     json=data,\n\u001b[32m     23\u001b[39m     headers=\u001b[38;5;28mself\u001b[39m._client._get_headers()\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
                  "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sripk\\OneDrive\\Documents\\Work\\axionic\\mechanex\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
                  "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: http://localhost:8000/generate",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[31mMechanexError\u001b[39m                             Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m test_prompt = \u001b[33m\"\u001b[39m\u001b[33mCurrently I feel: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m steered = \u001b[43mmx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteering_strength\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m original = mx.generation.generate(test_prompt)\n",
                  "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sripk\\OneDrive\\Documents\\Work\\axionic\\mechanex\\mechanex\\generation.py:9\u001b[39m, in \u001b[36mGenerationModule.generate\u001b[39m\u001b[34m(self, prompt, max_tokens, sampling_method, steering_strength)\u001b[39m\n\u001b[32m      5\u001b[39m def generate(self, prompt: str, max_tokens: int = 128, sampling_method: Optional[str] = \"top-k\", steering_strength=0) -> str:\n\u001b[32m      6\u001b[39m     \"\"\"\n\u001b[32m      7\u001b[39m     Runs a standard generation\n\u001b[32m      8\u001b[39m     \"\"\"\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     # Mechanex currently does not support steering and sampling simultaneously. \n\u001b[32m     10\u001b[39m     # This is an issue that exists primarily due to the ADS implementation.\n\u001b[32m     11\u001b[39m     if steering_strength > 0:\n\u001b[32m     12\u001b[39m         response = self._post(\"/steering/run\", {\n\u001b[32m     13\u001b[39m             \"prompt\": prompt,\n\u001b[32m     14\u001b[39m             \"max_tokens\": max_tokens,\n\u001b[32m     15\u001b[39m             \"multiplier\": steering_strength\n\u001b[32m     16\u001b[39m         })\n",
                  "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sripk\\OneDrive\\Documents\\Work\\axionic\\mechanex\\mechanex\\base.py:31\u001b[39m, in \u001b[36m_BaseModule._post\u001b[39m\u001b[34m(self, endpoint, data)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     30\u001b[39m     error_message += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m | Server response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.response.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m MechanexError(error_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
                  "\u001b[31mMechanexError\u001b[39m: API request to /generate failed: 400 Client Error: Bad Request for url: http://localhost:8000/generate | Server response: {\"detail\":\"No model loaded\"}"
               ]
            }
         ],
         "source": [
            "test_prompt = \"I am feeling so \"\n",
            "steered = mx.generation.generate(test_prompt, steering_strength=0.3, steering_vector=\"e74f687a-3d63-4478-a2d5-884ac72005a7\")\n",
            "original = mx.generation.generate(test_prompt)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6c37028b",
         "metadata": {},
         "source": [
            "Printing results:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "22c33a85",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Original:\n",
                  "I am feeling so  disasteric ... sorry for this long wind. I've tried so many times to post about my problems and how I really want to be successful, but I can't seem to find a place where I can post any longer. I finally decided to ask this in a thread so you can see and better help me out. I hope this forum isnt too weird. I know it's been years since I posted here last time. I just recently started my blog. \n",
                  "\n",
                  "I'm working on a Wordpress site with a PHP website and everything. I wanted to give it a full makeover but I never did it... I am really\n",
                  "\n",
                  "\n",
                  "\n",
                  "Steered:\n",
                  "I am feeling so 100% confident that you are all doing the best you can and being as meticulous as you can. We are here 24/7, and if you have any questions or concerns, leave us a comment (we are there for all of you), and we will do our best to make them known. As a note, a lot of things that go on in our team that are considered “business” or are not officially “solutions” can be important to our community. So, we have a number of “work-related” 24/7 teams to get the updates and information and updates. If you have\n",
                  "-------------------------\n"
               ]
            }
         ],
         "source": [
            "# Generate steered and original outputs\n",
            "print(\"Original:\")\n",
            "print(original)\n",
            "print(\"\\n\\n\")\n",
            "print(\"Steered:\")\n",
            "print(steered)\n",
            "print(\"-\" * 25)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "04e78936",
         "metadata": {},
         "source": [
            "We can also vary the sampling method of our original generation."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "08996f74",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Here is the story about the american civil war: Confederate and Union ships fought at the Battle of Hampton Roads on March 8, 1862.\n",
                  "The Union took the North Atlantic Blockading Squadron of the Confederate States of America, including the powerful flagship CSS Virginia, at Hampton Roads, where both sides were forced to make adjustments to the war of the Civil War. For two days in the spring of 1862, these ships fought in close quarters. After the ships were sunk one by one, the Virginia burned, the battle would become known as the Battle of Hampton Roads.\n",
                  "Battle of Hampton Roads History and Statistics\n",
                  "The Battle of the Battle of Hampton Roads was the second day of what\n"
               ]
            }
         ],
         "source": [
            "print(mx.generation.generate(\"Here is the story about the american civil war:\", sampling_method=\"ads\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "9b007aed",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 1. Generate steering vector from JSONL\n",
            "# (This still computes the vector first, which is often required)\n",
            "vector_response = mx.steering.generate_from_jsonl(\"./tests/example_dataset.jsonl\", method=\"caa\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "5b10b3df",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "5314e1e6-397c-4d6c-8195-bac2b693cadb\n"
               ]
            }
         ],
         "source": [
            "print(vector_response)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "92d7d635",
         "metadata": {},
         "outputs": [],
         "source": [
            "behavior = mx.sae.create_behavior_from_jsonl(\n",
            "    behavior_name=\"toxicity_improved\",\n",
            "    dataset_path=\"./tests/example_dataset.jsonl\",\n",
            "    description=\"Reduces toxic output\",\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "b273f34d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'behaviors': [{'id': '16f1668b-1839-4bf1-a979-d0d53a597e9a',\n",
                     "   'api_key_id': '48dd24ae-661e-46da-b3d1-97d59ddad50b',\n",
                     "   'steering_vector_id': '8019435c-4269-454b-8b14-e523eb3eed97',\n",
                     "   'behavior_name': 'toxicity',\n",
                     "   'sae_baseline_path': 'sae_baselines/f1ab48bf-e36b-4c74-8e96-dc40bb064e68/ed11ca1b2b2840a2a5f87509d470b2eb.npy',\n",
                     "   'description': None,\n",
                     "   'created_at': '2026-01-24T23:45:26.000699+00:00',\n",
                     "   'steering_vectors': {'id': '8019435c-4269-454b-8b14-e523eb3eed97',\n",
                     "    'nodes': ['transformer.h.8',\n",
                     "     'transformer.h.9',\n",
                     "     'transformer.h.10',\n",
                     "     'transformer.h.11'],\n",
                     "    'method': 'caa',\n",
                     "    'api_key_id': '48dd24ae-661e-46da-b3d1-97d59ddad50b',\n",
                     "    'created_at': '2026-01-24T23:07:41.596346+00:00',\n",
                     "    'model_name': 'remote',\n",
                     "    'storage_path': 'steering_vectors/f1ab48bf-e36b-4c74-8e96-dc40bb064e68/48dd24ae-661e-46da-b3d1-97d59ddad50b/848c07525db146e593bfe538fc982b1a.safetensors'}},\n",
                     "  {'id': 'dbfbbf8c-8ab3-42cc-a45a-e8357d78b260',\n",
                     "   'api_key_id': '48dd24ae-661e-46da-b3d1-97d59ddad50b',\n",
                     "   'steering_vector_id': 'ce9d27ad-bf43-4059-8e0f-0948fba94621',\n",
                     "   'behavior_name': 'toxicity_improved',\n",
                     "   'sae_baseline_path': 'sae_baselines/f1ab48bf-e36b-4c74-8e96-dc40bb064e68/59e78fdf2c59434b9b7d23919698479d.npy',\n",
                     "   'description': None,\n",
                     "   'created_at': '2026-01-27T17:22:05.839622+00:00',\n",
                     "   'steering_vectors': {'id': 'ce9d27ad-bf43-4059-8e0f-0948fba94621',\n",
                     "    'nodes': ['model.layers.18',\n",
                     "     'model.layers.19',\n",
                     "     'model.layers.20',\n",
                     "     'model.layers.21',\n",
                     "     'model.layers.22',\n",
                     "     'model.layers.23',\n",
                     "     'model.layers.24',\n",
                     "     'model.layers.25'],\n",
                     "    'method': 'caa',\n",
                     "    'api_key_id': '48dd24ae-661e-46da-b3d1-97d59ddad50b',\n",
                     "    'created_at': '2026-01-27T17:21:55.009448+00:00',\n",
                     "    'model_name': 'remote',\n",
                     "    'storage_path': 'steering_vectors/f1ab48bf-e36b-4c74-8e96-dc40bb064e68/48dd24ae-661e-46da-b3d1-97d59ddad50b/51858d0502bb4424a72ea9bd7fc21b17.safetensors'}}]}"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "mx.sae.list_behaviors()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "d95c5cda",
         "metadata": {},
         "outputs": [],
         "source": [
            "response = mx.sae.generate(\n",
            "    prompt=\"How are you feeling about life? I am feeling \",\n",
            "    max_new_tokens=50,\n",
            "    behavior_names=[\"toxicity_improved\"],\n",
            "    auto_correct=True,\n",
            "    force_steering=[\"toxicity_improved\"]\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "46c50d65",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "How are you feeling about life? I am feeling  grateful community service our family our family Community health team our newly successful leadership team our professional life our leadership family our our higher team our team our family Strong individual strength our family community leadership team our leadership community our team our families family our community our our team\n"
               ]
            }
         ],
         "source": [
            "print(response)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "bf23ac40",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "How are you feeling about life? I am feeling icky about this situation, but it's happening more and more to the point where I can't even think about it anymore. I think it's time I got to learn the \"why\" in life. A good person will go through it. It's not easy. It's difficult to live with. I have to. I have to. Even though one of the best things possible for me is to learn \"why\", I can't afford to stop thinking about it. I am trying hard. I am not at my best. I am doing just fine, just like I always want to do. I have a full body. I\n"
               ]
            }
         ],
         "source": [
            "print(mx.generation.generate(\"How are you feeling about life? I am feeling \", sampling_method=\"top-k\"))"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
